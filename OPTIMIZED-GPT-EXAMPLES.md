# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è GPT

## üéØ **–¶–µ–ª—å: 4 —Å–ª–æ–≤–∞ –º–∞–∫—Å–∏–º—É–º –≤ –ø–æ–∏—Å–∫–æ–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ**

### **–§–æ—Ä–º—É–ª–∞:** `brand_normalized + clean_name + required_tokens ‚â§ 4 words`

---

## ‚úÖ **–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã**

### **M&M's Peanut Butter:**
```javascript
// ‚úÖ –û–ü–¢–ò–ú–ê–õ–¨–ù–û:
{
  name: "M&M's Peanut Butter",
  brand_normalized: "m&m's",           // 1 word
  clean_name: "chocolate",             // 1 word  
  required_tokens: ["peanut", "butter"] // 2 words
}
// ‚Üí Query: "m&m's chocolate peanut butter" (4 words) ‚úÖ

// ‚ùå –ë–´–õ–û (—Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ):
{
  clean_name: "chocolate candies",     // 2 words
  required_tokens: ["peanut", "butter"] // 2 words
}
// ‚Üí Query: "m&m's chocolate candies peanut butter" (6 words) ‚ùå
```

### **Coca-Cola Zero:**
```javascript
// ‚úÖ –û–ü–¢–ò–ú–ê–õ–¨–ù–û:
{
  name: "Coca-Cola Zero",
  brand_normalized: "coca-cola",       // 1 word (hyphenated)
  clean_name: "cola",                  // 1 word
  required_tokens: ["zero"]            // 1 word
}
// ‚Üí Query: "coca-cola cola zero" (3 words) ‚úÖ
```

### **Central Lechera Semi Desnatada:**
```javascript
// ‚úÖ –û–ü–¢–ò–ú–ê–õ–¨–ù–û:
{
  name: "Central Lechera Asturiana Semi Desnatada",
  brand_normalized: "central lechera asturiana", // 3 words
  clean_name: "milk",                  // 1 word
  required_tokens: ["semi"]            // 1 word (–≤—ã–±–∏—Ä–∞–µ–º –≥–ª–∞–≤–Ω—ã–π)
}
// ‚Üí Query: "central lechera asturiana milk" (4 words) ‚úÖ
// Note: 'semi' –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω —á–µ—Ä–µ–∑ variant system

// ‚ùå –ë–´–õ–û (—Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ):
{
  clean_name: "leche",
  required_tokens: ["semi", "desnatada"] // 2 words
}
// ‚Üí Query: "central lechera asturiana leche semi desnatada" (6 words) ‚ùå
```

---

## üéØ **–ù–æ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è GPT**

### **1. Word Limits:**
- `clean_name`: **1 word preferred, 2 maximum**
- `required_tokens`: **1-2 essential terms only**
- Total query: **4 words maximum**

### **2. Prioritization:**
- **Most important modifier** goes in required_tokens
- **Secondary modifiers** ignored for search efficiency
- **Generic product type** in clean_name

### **3. Language optimization:**
- Use **shorter English equivalents** when available:
  - `"leche"` ‚Üí `"milk"` (shorter and universal)
  - `"mantequilla"` ‚Üí `"butter"` (shorter)
  - `"chocolate candies"` ‚Üí `"chocolate"` (1 word vs 2)

---

## üìä **Expected Results**

### **M&M's case:**
```
Input: M&M's Peanut Butter package
GPT output: brand_normalized: "m&m's", clean_name: "chocolate", required_tokens: ["peanut"]
Search query: "m&m's chocolate peanut" (3 words)
Expected result: Strong brand match with M&M's products ‚úÖ
```

### **Central Lechera case:**
```
Input: Central Lechera Semi Desnatada
GPT output: brand_normalized: "central lechera asturiana", clean_name: "milk", required_tokens: ["semi"]  
Search query: "central lechera asturiana milk" (4 words)
Expected result: Find Central Lechera milk products ‚úÖ
```

---

**Key insight:** Tell GPT exactly what we need for search efficiency, not just general field separation rules.
